{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f32e51c-9955-46d4-afdb-723481053a82",
   "metadata": {},
   "source": [
    "# Document Layout Clustering - embedding generation\n",
    "\n",
    "Here we generate embeddings for a number of pages in each document using a general purpose VGG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a795e7be-1884-4c95-ac6a-77545fd24727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kalyan/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/kalyan/Documents/CPR/policy-search/data/corpus/content'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import typing as t\n",
    "\n",
    "import fitz\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\n",
    "CORPUS_PATH = os.getenv(\"CORPUS_PATH\")\n",
    "\n",
    "CORPUS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c91e71a1-f02d-440b-b33f-feaa883fe9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2824"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_files = glob.glob(f\"{CORPUS_PATH}/*.pdf\") + glob.glob(f\"{CORPUS_PATH}/*.PDF\")\n",
    "len(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7516db0e-e349-411d-94f9-a821eac69ca0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     shortlisted_files\u001b[38;5;241m.\u001b[39mupdate( {key : timestamp} )   \n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m shortlisted_files\n\u001b[0;32m---> 35\u001b[0m pdf_files \u001b[38;5;241m=\u001b[39m \u001b[43ms3_glob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS3_BUCKET\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, \".pdf\")\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Local\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# pdf_files = glob.glob(f\"{CORPUS_PATH}/*.pdf\") + glob.glob(f\"{CORPUS_PATH}/*.PDF\")\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mlen\u001b[39m(pdf_files)\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36ms3_glob\u001b[0;34m(bucket_name, suffix)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21ms3_glob\u001b[39m(bucket_name, suffix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      6\u001b[0m     s3_client \u001b[38;5;241m=\u001b[39m boto3\u001b[38;5;241m.\u001b[39mclient(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     s3_result \u001b[38;5;241m=\u001b[39m \u001b[43ms3_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_objects_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     shortlisted_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()            \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m s3_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContents\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/CPR/pdf-corpus-analysis/.venv/lib/python3.8/site-packages/botocore/client.py:391\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m py_operation_name)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/CPR/pdf-corpus-analysis/.venv/lib/python3.8/site-packages/botocore/client.py:719\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    717\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    718\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied"
     ]
    }
   ],
   "source": [
    "# S3\n",
    "S3_BUCKET=\"cpr-cclw-cpd-docs-temp\"\n",
    "import boto3\n",
    "\n",
    "def s3_glob(bucket_name, suffix = None):\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_result = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "    shortlisted_files = dict()            \n",
    "    for obj in s3_result['Contents']:\n",
    "        key = obj['Key']\n",
    "        timestamp = obj['LastModified']\n",
    "        \n",
    "        if suffix:\n",
    "            if key.endswith(suffix):              \n",
    "                # Adding a new key value pair\n",
    "                shortlisted_files.update( {key : timestamp} )   \n",
    "        else:\n",
    "            shortlisted_files.update( {key : timestamp} )   \n",
    "    \n",
    "    while s3_result['IsTruncated']:\n",
    "        continuation_key = s3_result['NextContinuationToken']\n",
    "        s3_result = s3_client.list_objects_v2(Bucket=bucket_name, ContinuationToken=continuation_key)\n",
    "        \n",
    "        for key in s3_result['Contents']:\n",
    "            if suffix:\n",
    "                if key.endswith(suffix):              \n",
    "                    # Adding a new key value pair\n",
    "                    shortlisted_files.update( {key : timestamp} )   \n",
    "                else:\n",
    "                    shortlisted_files.update( {key : timestamp} )   \n",
    "    \n",
    "    return shortlisted_files\n",
    "\n",
    "\n",
    "pdf_files = s3_glob(S3_BUCKET)#, \".pdf\")\n",
    "\n",
    "# Local\n",
    "# pdf_files = glob.glob(f\"{CORPUS_PATH}/*.pdf\") + glob.glob(f\"{CORPUS_PATH}/*.PDF\")\n",
    "len(pdf_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018d353-5ebf-40a5-af8d-d17f4463a2f7",
   "metadata": {},
   "source": [
    "## 1. Define pages to process for each document\n",
    "\n",
    "This is so we don't have to process all the pages in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7deb3502-9c0b-489a-a37b-4471fd328ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_locs_from_doc(doc: fitz.Document, n: int) -> t.List[int]:\n",
    "    \"\"\"\n",
    "    Get indices for `n` evenly spaced pages from the doc, excluding the last page. \n",
    "    Returns all the pages excluding the last if there are fewer than `n` pages in the doc (excluding the last).\n",
    "    \"\"\"\n",
    "    \n",
    "    if n < len(doc):\n",
    "        return [int(i) for i in np.linspace(0, len(doc)-2 , n).tolist()]\n",
    "    else:\n",
    "        return list(range(len(doc)))\n",
    "\n",
    "MAX_PAGES_PER_DOC = 6    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e85b93-2852-4b95-9cc0-935da894811c",
   "metadata": {},
   "source": [
    "## 2. Run processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "efe667ec-b241-4205-b857-970a84507ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_to_image(page: 'Page') -> Image:\n",
    "    pix = page.get_pixmap()\n",
    "    input_bytes = pix.pil_tobytes(format=\"JPEG\")\n",
    "\n",
    "    return Image.open(io.BytesIO(input_bytes))\n",
    "\n",
    "def image_to_emb_vector(img: Image, model: torch.nn) -> torch.Tensor:\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # output = model(input_batch)\n",
    "        fl_embedding = model.features(input_batch)\n",
    "\n",
    "    return fl_embedding[0].reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf1d2dbf-2ae9-4c19-95b6-55fe52b0d107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d015888507b4dbda3260d954287af23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_store = []\n",
    "\n",
    "for f_name in tqdm(pdf_files[0:9]):\n",
    "    doc = fitz.open(f_name)\n",
    "    page_idxs_to_process = page_locs_from_doc(doc, MAX_PAGES_PER_DOC)\n",
    "    \n",
    "    for idx in page_idxs_to_process:\n",
    "        input_image = page_to_image(doc.load_page(idx))\n",
    "        emb = image_to_emb_vector(input_image, model)\n",
    "        \n",
    "        embedding_store.append(\n",
    "            {\n",
    "                \"filename\": f_name,\n",
    "                \"page_num\": idx,\n",
    "                \"embedding\": emb.tolist()\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # display(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91058b5-9f9c-45f3-8bc6-31aa8e302e39",
   "metadata": {},
   "source": [
    "### Save embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ee45c3a-ef75-44a9-a98c-0c5e1fafa6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(embedding_store).to_pickle(\"vgg16_embeddings.pkl\")\n",
    "pd.DataFrame(embedding_store).to_csv(\"vgg16_embeddings.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab8d11-543c-4423-bc05-57c3518724d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
