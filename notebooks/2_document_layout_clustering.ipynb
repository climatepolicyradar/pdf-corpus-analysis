{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f32e51c-9955-46d4-afdb-723481053a82",
   "metadata": {},
   "source": [
    "# Document Layout Clustering - embedding generation\n",
    "\n",
    "Here we generate embeddings for a number of pages in each document using a general purpose VGG model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a795e7be-1884-4c95-ac6a-77545fd24727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kalyan/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/kalyan/Documents/CPR/policy-search/data/corpus/content'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import typing as t\n",
    "\n",
    "import fitz\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\n",
    "CORPUS_PATH = os.getenv(\"CORPUS_PATH\")\n",
    "\n",
    "CORPUS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c91e71a1-f02d-440b-b33f-feaa883fe9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2824"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_files = glob.glob(f\"{CORPUS_PATH}/*.pdf\") + glob.glob(f\"{CORPUS_PATH}/*.PDF\")\n",
    "len(pdf_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018d353-5ebf-40a5-af8d-d17f4463a2f7",
   "metadata": {},
   "source": [
    "## 1. Define pages to process for each document\n",
    "\n",
    "This is so we don't have to process all the pages in each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7deb3502-9c0b-489a-a37b-4471fd328ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_locs_from_doc(doc: fitz.Document, n: int) -> t.List[int]:\n",
    "    \"\"\"\n",
    "    Get indices for `n` evenly spaced pages from the doc, excluding the last page. \n",
    "    Returns all the pages excluding the last if there are fewer than `n` pages in the doc (excluding the last).\n",
    "    \"\"\"\n",
    "    \n",
    "    if n < len(doc):\n",
    "        return [int(i) for i in np.linspace(0, len(doc)-2 , n).tolist()]\n",
    "    else:\n",
    "        return list(range(len(doc)))\n",
    "\n",
    "MAX_PAGES_PER_DOC = 6    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e85b93-2852-4b95-9cc0-935da894811c",
   "metadata": {},
   "source": [
    "## 2. Run processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "efe667ec-b241-4205-b857-970a84507ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_to_image(page: 'Page') -> Image:\n",
    "    pix = page.get_pixmap()\n",
    "    input_bytes = pix.pil_tobytes(format=\"JPEG\")\n",
    "\n",
    "    return Image.open(io.BytesIO(input_bytes))\n",
    "\n",
    "def image_to_emb_vector(img: Image, model: torch.nn) -> torch.Tensor:\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # output = model(input_batch)\n",
    "        fl_embedding = model.features(input_batch)\n",
    "\n",
    "    return fl_embedding[0].reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf1d2dbf-2ae9-4c19-95b6-55fe52b0d107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d015888507b4dbda3260d954287af23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_store = []\n",
    "\n",
    "for f_name in tqdm(pdf_files[0:9]):\n",
    "    doc = fitz.open(f_name)\n",
    "    page_idxs_to_process = page_locs_from_doc(doc, MAX_PAGES_PER_DOC)\n",
    "    \n",
    "    for idx in page_idxs_to_process:\n",
    "        input_image = page_to_image(doc.load_page(idx))\n",
    "        emb = image_to_emb_vector(input_image, model)\n",
    "        \n",
    "        embedding_store.append(\n",
    "            {\n",
    "                \"filename\": f_name,\n",
    "                \"page_num\": idx,\n",
    "                \"embedding\": emb.tolist()\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # display(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91058b5-9f9c-45f3-8bc6-31aa8e302e39",
   "metadata": {},
   "source": [
    "### Save embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ee45c3a-ef75-44a9-a98c-0c5e1fafa6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(embedding_store).to_pickle(\"vgg16_embeddings.pkl\")\n",
    "pd.DataFrame(embedding_store).to_csv(\"vgg16_embeddings.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab8d11-543c-4423-bc05-57c3518724d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
